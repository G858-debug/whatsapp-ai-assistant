# .github/workflows/test_and_fix.yml
name: Test Conversations & Auto-Fix

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:  # Allow manual trigger
    inputs:
      fix_mode:
        description: 'Auto-fix mode'
        required: false
        default: 'auto'
        type: choice
        options:
          - auto
          - manual
          - report-only

jobs:
  test-conversations:
    runs-on: ubuntu-latest
    
    env:
      SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
      SUPABASE_ANON_KEY: ${{ secrets.SUPABASE_ANON_KEY }}
      SUPABASE_SERVICE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
      ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
      WHATSAPP_TOKEN: ${{ secrets.WHATSAPP_TOKEN }}
      WHATSAPP_PHONE_ID: ${{ secrets.WHATSAPP_PHONE_ID }}
      TIMEZONE: 'Africa/Johannesburg'
      TEST_PHONE: '27731863036'
      
    steps:
    - uses: actions/checkout@v3
      with:
        fetch-depth: 0
        token: ${{ secrets.GITHUB_TOKEN }}
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Cache dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-cov pytest-html pytest-json-report colorama
    
    - name: Debug - Check environment
      run: |
        echo "=== Checking environment ==="
        echo "Current directory: $(pwd)"
        echo "Directory contents:"
        ls -la
        echo ""
        echo "Python path:"
        python -c "import sys; print('\n'.join(sys.path))"
        echo ""
        echo "Installed packages:"
        pip list | head -20
    
    - name: Setup test environment
      run: |
        echo "Setting up test environment..."
        # Check if setup file exists
        if [ -f "tests/setup_test_env.py" ]; then
          python tests/setup_test_env.py
        else
          echo "Setup file not found, skipping..."
        fi
    
    - name: Run debug test first
      continue-on-error: true
      run: |
        echo "Running debug test to identify issues..."
        python tests/test_debug.py || true
    
    - name: Run conversation flow tests
      id: run-tests
      continue-on-error: true
      run: |
        echo "Running comprehensive real-world tests..."
        
        # Create default results in case tests fail to run
        echo '{"summary": {"total": 0, "passed": 0, "failed": 0}, "tests": []}' > test-results.json
        echo "<html><body>Tests not run</body></html>" > test-report.html
        
        # First, try to run the comprehensive real-world tests
        if [ -f "tests/test_refiloe_real_world.py" ]; then
          echo "Running real-world comprehensive tests..."
          python -m pytest tests/test_refiloe_real_world.py \
            --html=test-report.html \
            --self-contained-html \
            --json-report \
            --json-report-file=test-results.json \
            -v \
            --tb=short \
            --capture=no 2>&1 | tee test-output.log
          TEST_EXIT_CODE=$?
        else
          echo "Real-world tests not found, running basic tests..."
          python -m pytest tests/ \
            --ignore=tests/test_railway_api.py \
            --ignore=tests/test_calendar_service.py \
            --html=test-report.html \
            --self-contained-html \
            --json-report \
            --json-report-file=test-results.json \
            -v \
            --tb=short \
            --capture=no 2>&1 | tee test-output.log
          TEST_EXIT_CODE=$?
        fi
        
        if [ $TEST_EXIT_CODE -eq 0 ]; then
          echo "âœ… All tests passed!"
          echo "test_status=success" >> $GITHUB_ENV
        else
          echo "âŒ Some tests failed (exit code: $TEST_EXIT_CODE)"
          echo "test_status=failure" >> $GITHUB_ENV
          
          # Show failed tests
          echo "=== Failed Tests ==="
          grep -E "FAILED|ERROR" test-output.log | head -20 || true
        fi
        
        # Always show test summary
        if [ -f "test-results.json" ]; then
          echo "=== Test Summary ==="
          python tests/show_summary.py || echo "Summary script not found"
        fi
    
    - name: Upload test results
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: test-results
        path: |
          test-report.html
          test-results.json
          test-output.log
    
    - name: Display test results
      if: always()
      run: |
        echo "=== Displaying Test Results ==="
        
        # Show JSON results if available
        if [ -f "test-results.json" ]; then
          echo "Test Results JSON:"
          cat test-results.json | python -m json.tool | head -100 || true
          
          # Extract and show failed tests
          echo ""
          echo "=== Failed Tests ==="
          python tests/show_failed_tests.py || echo "No failed test script"
        else
          echo "No test results JSON found"
        fi
    
    - name: Create helper scripts
      if: steps.run-tests.outcome == 'failure' || failure()
      run: |
        # Create show_summary.py
        cat > tests/show_summary.py << 'EOF'
import json
with open('test-results.json') as f:
    data = json.load(f)
    summary = data.get('summary', {})
    print(f"Total: {summary.get('total', 0)}")
    print(f"Passed: {summary.get('passed', 0)}")
    print(f"Failed: {summary.get('failed', 0)}")
EOF
        
        # Create show_failed_tests.py
        cat > tests/show_failed_tests.py << 'EOF'
import json
try:
    with open('test-results.json') as f:
        data = json.load(f)
        for test in data.get('tests', []):
            if test.get('outcome') == 'failed':
                print(f"âŒ {test.get('nodeid', 'Unknown test')}")
except Exception as e:
    print(f'Could not parse results: {e}')
EOF
        
        # Create count_failures.py
        cat > tests/count_failures.py << 'EOF'
import json
with open('test-results.json') as f:
    data = json.load(f)
    failed = len([t for t in data.get('tests', []) if t.get('outcome') == 'failed'])
    print(failed)
EOF
    
    - name: Analyze failures and generate fixes
      id: analyze-fixes
      if: steps.run-tests.outcome == 'failure' || failure()
      run: |
        echo "=== Starting Fix Analysis ==="
        
        # Check test results
        if [ -f "test-results.json" ]; then
          echo "Test results found, checking for failures..."
          
          # Count failures
          FAILED_COUNT=$(python tests/count_failures.py)
          
          echo "Found $FAILED_COUNT failed tests"
          
          if [ "$FAILED_COUNT" -gt 0 ]; then
            echo "Generating fixes..."
            
            # Check if fix generator exists
            if [ ! -f "tests/auto_fix_generator.py" ]; then
              echo "Creating auto_fix_generator.py..."
              cat > tests/auto_fix_generator.py << 'EOF'
#!/usr/bin/env python3
import json
import os

def generate_fixes():
    """Generate fixes based on test failures"""
    
    with open('test-results.json', 'r') as f:
        results = json.load(f)
    
    fixes = []
    for test in results.get('tests', []):
        if test.get('outcome') == 'failed':
            test_name = test.get('nodeid', '')
            error = str(test.get('call', {}).get('longrepr', ''))
            
            # Currency parsing fix
            if 'pricing' in test_name.lower() or "'R450' == 450" in error:
                fixes.append({
                    'type': 'currency_parsing',
                    'file': 'services/registration/trainer_registration.py',
                    'test': test_name,
                    'diagnosis': 'Currency value saved as string instead of number',
                    'line': 100,
                    'original_code': "'pricing_per_session': data.get('pricing', 400),",
                    'fixed_code': "'pricing_per_session': float(str(data.get('pricing', 400)).replace('R', '').replace(',', '').strip()),"
                })
            
            # Phone format fix
            if 'phone' in test_name.lower() and '+27' in error:
                fixes.append({
                    'type': 'phone_format',
                    'file': 'utils/validators.py',
                    'test': test_name,
                    'diagnosis': 'Phone returns with + prefix',
                    'line': 50,
                    'original_code': "return True, f'+{phone_digits}', None",
                    'fixed_code': "return True, phone_digits, None"
                })
    
    with open('generated_fixes.json', 'w') as f:
        json.dump(fixes, f, indent=2)
    
    print(f"Generated {len(fixes)} fixes")
    return len(fixes) > 0

if __name__ == "__main__":
    generate_fixes()
EOF
            fi
            
            # Run fix generator
            if python tests/auto_fix_generator.py; then
              echo "Fix generator completed"
              
              # Check if fixes were generated
              if [ -f "generated_fixes.json" ]; then
                echo "Fixes generated successfully:"
                cat generated_fixes.json | python -m json.tool | head -50
                echo "fixes_generated=true" >> $GITHUB_ENV
              else
                echo "âš ï¸ No fixes file created"
                echo "fixes_generated=false" >> $GITHUB_ENV
              fi
            else
              echo "âŒ Fix generator failed"
              echo "fixes_generated=false" >> $GITHUB_ENV
            fi
          else
            echo "No failures to fix"
            echo "fixes_generated=false" >> $GITHUB_ENV
          fi
        else
          echo "âŒ No test results found"
          echo "fixes_generated=false" >> $GITHUB_ENV
        fi
    
    - name: Apply auto-fixes and create PR
      if: env.fixes_generated == 'true' && github.event.inputs.fix_mode != 'report-only'
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      run: |
        echo "=== Applying Fixes ==="
        
        # Configure git
        git config --global user.name 'Refiloe Auto-Fix Bot'
        git config --global user.email 'bot@refiloe.ai'
        
        # Create fix branch
        BRANCH_NAME="auto-fix-$(date +%Y%m%d-%H%M%S)"
        git checkout -b $BRANCH_NAME
        
        # Check if apply_fixes.py exists, if not create it
        if [ ! -f "tests/apply_fixes.py" ]; then
          echo "Creating apply_fixes.py..."
          cat > tests/apply_fixes.py << 'EOF'
#!/usr/bin/env python3
import json
import os
import re

def apply_fixes():
    """Apply generated fixes to files"""
    
    if not os.path.exists('generated_fixes.json'):
        print("No fixes to apply")
        return False
    
    with open('generated_fixes.json', 'r') as f:
        fixes = json.load(f)
    
    files_modified = False
    
    for fix in fixes:
        file_path = fix['file']
        if os.path.exists(file_path):
            with open(file_path, 'r') as f:
                content = f.read()
            
            # Apply simple replacement
            if fix.get('original_code') and fix['original_code'] in content:
                content = content.replace(fix['original_code'], fix['fixed_code'])
                with open(file_path, 'w') as f:
                    f.write(content)
                print(f"Fixed {file_path}")
                files_modified = True
    
    return files_modified

if __name__ == "__main__":
    import sys
    sys.exit(0 if apply_fixes() else 1)
EOF
        fi
        
        # Apply fixes
        python tests/apply_fixes.py || echo "Apply fixes had issues"
        
        # Check if any files were changed
        if [[ -n $(git status -s) ]]; then
          echo "Files were modified, creating PR..."
          
          git add -A
          git commit -m "ğŸ”§ Auto-fix: Resolve conversation flow issues"
          git push origin $BRANCH_NAME
          
          # Create PR using gh CLI
          gh pr create \
            --title "ğŸ”§ Auto-Fix: Conversation Flow Issues" \
            --body "Automated fixes for test failures in registration and validation" \
            --base main \
            --head $BRANCH_NAME \
            --label "auto-fix" \
            --assignee ${{ github.actor }} || echo "PR creation had issues"
        else
          echo "No files were changed after applying fixes"
        fi
    
    - name: Post test summary to PR
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v6
      with:
        script: |
          const fs = require('fs');
          const results = JSON.parse(fs.readFileSync('test-results.json', 'utf8'));
          
          const passed = results.tests.filter(t => t.outcome === 'passed').length;
          const failed = results.tests.filter(t => t.outcome === 'failed').length;
          const total = results.tests.length;
          
          const emoji = failed === 0 ? 'âœ…' : 'âŒ';
          const status = failed === 0 ? 'All tests passed!' : `${failed} test(s) failed`;
          
          const comment = `## ${emoji} Conversation Flow Test Results
          
          **Status:** ${status}
          **Passed:** ${passed}/${total}
          
          [View detailed report](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})`;
          
          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: comment
          });
    
    - name: Cleanup test data
      if: always()
      run: |
        echo "Cleaning up test data from Supabase..."
        python tests/cleanup_test_data.py || echo "Cleanup script not found or failed"
    
    - name: Celebrate success
      if: success() && steps.run-tests.outcome == 'success'
      run: |
        echo "ğŸ‰ğŸ‰ğŸ‰ ALL TESTS PASSED! ğŸ‰ğŸ‰ğŸ‰"
        echo "================================"
        echo "âœ… Test suite is working correctly"
        echo "âœ… All conversation flows passed"
        echo "âœ… No fixes needed"
        echo "================================"

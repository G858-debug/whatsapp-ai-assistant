name: Claude Code Assistant
on:
  issue_comment:
    types: [created]

permissions:
  contents: write
  issues: write
  pull-requests: write

jobs:
  claude:
    if: contains(github.event.comment.body, '@claude')
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          fetch-depth: 0
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Install Dependencies
        run: |
          pip install anthropic
          pip install supabase
          pip install gitpython
          pip install unidiff
      
      - name: Configure Git
        run: |
          git config --global user.name "Claude Assistant"
          git config --global user.email "claude@github-actions.bot"
      
      - name: Save comment to file
        run: |
          cat > comment.txt << 'ENDOFCOMMENT'
          ${{ github.event.comment.body }}
          ENDOFCOMMENT
      
      - name: Process with Claude and Apply Changes
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          python - <<'PYTHON_SCRIPT'
          import anthropic
          import os
          import json
          import re
          from pathlib import Path
          import subprocess
          from datetime import datetime
          
          # Read the task
          with open('comment.txt', 'r') as f:
              comment = f.read()
          task = comment.replace('@claude', '').strip()
          
          print(f"üìã Task: {task}")
          
          # Check for special commands
          auto_apply = '@apply' in comment or '@commit' in comment
          create_pr = '@pr' in comment
          force_opus = '@opus' in comment
          force_sonnet = '@sonnet' in comment
          force_haiku = '@haiku' in comment
          continue_task = '@continue' in comment  # SOLUTION 5: Continue command
          
          # Remove command keywords from task
          clean_task = task.replace('@apply', '').replace('@commit', '').replace('@pr', '')\
                           .replace('@opus', '').replace('@sonnet', '').replace('@haiku', '')\
                           .replace('@continue', '').strip()
          
          # =====================================
          # SOLUTION 6: STREAMING FOR LONG OPERATIONS
          # =====================================
          def check_if_multi_step_task(task_lower):
              """Check if task requires multiple steps"""
              multi_step_triggers = [
                  'refactor all', 'update entire', 'fix all', 'complete implementation',
                  'implement full', 'create complete', 'build entire', 'redesign',
                  'migrate everything', 'update all', 'fix everything', 'comprehensive',
                  'all files', 'entire codebase', 'full system', 'complete system'
              ]
              return any(trigger in task_lower for trigger in multi_step_triggers)
          
          def break_into_steps(task_lower, clean_task):
              """Break complex task into manageable steps"""
              steps = []
              
              # Gamification implementation
              if 'gamification' in task_lower:
                  steps = [
                      "Step 1: Create database schema for gamification (tables, migrations)",
                      "Step 2: Implement core gamification service (badges, points, challenges)",
                      "Step 3: Create leaderboard system and rankings",
                      "Step 4: Add dashboard routes and API endpoints",
                      "Step 5: Integrate with existing services (habits, workouts, assessments)"
                  ]
              # Refactoring tasks
              elif 'refactor' in task_lower:
                  steps = [
                      "Step 1: Analyze current code structure and identify issues",
                      "Step 2: Split large files (>600 lines) into modules",
                      "Step 3: Extract shared utilities and helpers",
                      "Step 4: Update imports and dependencies",
                      "Step 5: Test and validate changes"
                  ]
              # Fix all errors
              elif 'fix all' in task_lower or 'fix everything' in task_lower:
                  steps = [
                      "Step 1: Fix critical syntax errors blocking deployment",
                      "Step 2: Fix import and dependency issues",
                      "Step 3: Fix database and model errors",
                      "Step 4: Fix service layer issues",
                      "Step 5: Fix remaining warnings and optimize"
                  ]
              # Update entire system
              elif 'update entire' in task_lower or 'update all' in task_lower:
                  steps = [
                      "Step 1: Update core configuration and dependencies",
                      "Step 2: Update database models and migrations",
                      "Step 3: Update service layer components",
                      "Step 4: Update API routes and endpoints",
                      "Step 5: Update frontend/templates and documentation"
                  ]
              # Default multi-step
              else:
                  steps = [
                      "Step 1: Analyze requirements and current state",
                      "Step 2: Implement core functionality",
                      "Step 3: Add supporting features",
                      "Step 4: Integrate with existing system",
                      "Step 5: Test and document changes"
                  ]
              
              return steps
          
          # SOLUTION 5: Handle continue command
          current_step = 1
          if continue_task:
              # Check for previous context
              if Path('claude_context.json').exists():
                  with open('claude_context.json', 'r') as f:
                      previous_context = json.load(f)
                  print(f"üìÇ Continuing from previous task: {previous_context.get('task', 'unknown')}")
                  print(f"üìç Current step: {previous_context.get('current_step', 1)}")
                  
                  clean_task = previous_context['task']
                  current_step = previous_context.get('current_step', 1) + 1
                  
                  # Use the same model as before if specified
                  if previous_context.get('model'):
                      if 'opus' in previous_context['model']:
                          force_opus = True
                      elif 'sonnet' in previous_context['model']:
                          force_sonnet = True
                      elif 'haiku' in previous_context['model']:
                          force_haiku = True
              else:
                  print("‚ö†Ô∏è No previous context found for @continue")
                  clean_task = "No previous context found. Please specify what to continue."
          
          # SOLUTION 6: Check if task needs multiple steps
          task_lower = clean_task.lower()
          is_multi_step = check_if_multi_step_task(task_lower)
          steps = []
          
          if is_multi_step and not continue_task:
              steps = break_into_steps(task_lower, clean_task)
              print("\nüìã This will be done in multiple steps:")
              for step in steps:
                  print(f"  {'‚úÖ' if steps.index(step) < current_step - 1 else '‚û°Ô∏è' if steps.index(step) == current_step - 1 else '‚è≥'} {step}")
              
              # Focus on current step
              if current_step <= len(steps):
                  clean_task = f"{clean_task}\n\nFOCUS ON: {steps[current_step - 1]}\nThis is step {current_step} of {len(steps)}."
              else:
                  print("‚úÖ All steps completed!")
                  clean_task = f"{clean_task}\n\nFinal review and cleanup."
          
          # =====================================
          # ENHANCED MODEL SELECTION WITH INCREASED TOKENS (SOLUTION 1)
          # =====================================
          def select_model_and_context(task, comment):
              """Select model based on task complexity with increased token limits"""
              
              task_lower = task.lower()
              
              # Force model if specified
              if force_opus:
                  print("üéØ Force flag: Using Opus 4.1")
                  return 'claude-opus-4-1-20250805', 32000, 'full', "Opus 4.1 (forced)"
              
              if force_sonnet:
                  print("üéØ Force flag: Using Sonnet 4")
                  return 'claude-sonnet-4-20250822', 8000, 'targeted', "Sonnet 4 (forced)"
              
              if force_haiku:
                  print("üéØ Force flag: Using Haiku 3")
                  return 'claude-3-haiku-20240307', 4000, 'minimal', "Haiku 3 (forced)"
              
              # For multi-step tasks, use appropriate model based on step
              if is_multi_step:
                  if 'analyze' in task_lower or 'step 1' in task_lower:
                      return 'claude-sonnet-4-20250822', 8000, 'targeted', "Analysis step (Sonnet 4)"
                  elif 'implement' in task_lower or 'create' in task_lower:
                      return 'claude-opus-4-1-20250805', 16000, 'full', "Implementation step (Opus 4.1)"
                  else:
                      return 'claude-sonnet-4-20250822', 8000, 'targeted', "Standard step (Sonnet 4)"
              
              # HAIKU 3 TRIGGERS (Ultra-simple tasks - $0.25/million tokens)
              haiku_triggers = [
                  'fix typo', 'fix spelling', 'update comment', 'fix comma',
                  'add space', 'remove space', 'fix quote', 'fix bracket',
                  'fix emoji', 'fix string', 'fix f-string', 'syntax error line',
                  'change text', 'update string', 'rename variable',
                  'update version', 'change url', 'fix link'
              ]
              
              # SONNET 4 TRIGGERS (Moderate tasks - $3/million tokens)
              sonnet_triggers = [
                  'fix function', 'update method', 'fix indentation', 'indentationerror',
                  'syntax error', 'fix import', 'add validation', 'add check',
                  'fix payment', 'fix error in', 'deployment crash',
                  'add endpoint', 'simple feature', 'add field', 'update model',
                  'single file', 'one file', 'specific function'
              ]
              
              # OPUS 4.1 TRIGGERS (Complex tasks - $15/million tokens)
              opus_triggers = [
                  'architect', 'design system', 'restructure', 'refactor entire',
                  'all files', 'entire codebase', 'multiple services', 'full system',
                  'complete implementation', 'finish all',
                  'analyze', 'investigate', 'debug complex', 'trace bug',
                  'performance', 'security audit', 'code review'
              ]
              
              # Check triggers
              is_haiku = any(trigger in task_lower for trigger in haiku_triggers)
              is_sonnet = any(trigger in task_lower for trigger in sonnet_triggers)
              is_opus = any(trigger in task_lower for trigger in opus_triggers)
              
              # Decision logic with increased token limits
              if is_haiku and not is_sonnet and not is_opus:
                  return 'claude-3-haiku-20240307', 4000, 'minimal', "Trivial task (Haiku 3)"
              elif is_sonnet and not is_opus:
                  return 'claude-sonnet-4-20250822', 8000, 'targeted', "Moderate task (Sonnet 4)"
              elif is_opus:
                  return 'claude-opus-4-1-20250805', 16000, 'full', "Complex task (Opus 4.1)"
              elif len(task) < 50:
                  return 'claude-3-haiku-20240307', 4000, 'minimal', "Short request (Haiku 3)"
              elif len(task) < 150:
                  return 'claude-sonnet-4-20250822', 8000, 'targeted', "Standard task (Sonnet 4)"
              else:
                  return 'claude-opus-4-1-20250805', 16000, 'full', "Long request (Opus 4.1)"
          
          # Select model
          selected_model, max_tokens, context_level, model_reason = select_model_and_context(task, comment)
          model_name = "Opus 4.1" if "opus" in selected_model else "Sonnet 4" if "sonnet" in selected_model else "Haiku 3"
          
          print(f"ü§ñ Model: {model_name}")
          print(f"üìù Reason: {model_reason}")
          print(f"üî¢ Max tokens: {max_tokens:,}")
          
          # =====================================
          # CONTEXT BUILDING BASED ON MODEL
          # =====================================
          def build_context_for_model(task, all_files, context_level):
              """Build appropriate context based on model/task"""
              
              task_lower = task.lower()
              
              # Always start with structure
              context = "=== PROJECT STRUCTURE ===\n"
              for file_path in sorted(all_files.keys())[:50]:  # Limit structure list
                  context += f"- {file_path}\n"
              
              # MINIMAL context (Haiku - just target file)
              if context_level == 'minimal':
                  # Find the specific file mentioned
                  target_file = None
                  for file_path in all_files.keys():
                      if file_path in task or Path(file_path).stem in task_lower:
                          target_file = file_path
                          break
                  
                  # Default to services/refiloe.py if it's a deployment error
                  if not target_file and ('deployment' in task_lower or 'crash' in task_lower):
                      target_file = 'services/refiloe.py'
                  
                  if target_file and target_file in all_files:
                      context += f"\n=== TARGET FILE: {target_file} ===\n"
                      lines = all_files[target_file].split('\n')
                      for i, line in enumerate(lines, 1):
                          context += f"{i:4}: {line}\n"
                  return context
              
              # TARGETED context (Sonnet - relevant files only)
              elif context_level == 'targeted':
                  relevant_files = set()
                  
                  # Keyword mappings - expanded for multi-step operations
                  keyword_mappings = {
                      'payment': ['payment_manager.py', 'services/payment.py'],
                      'gamification': ['services/gamification.py', 'routes/dashboard.py', 'templates/challenge_hub.html'],
                      'assessment': ['services/assessment.py'],
                      'refiloe': ['services/refiloe.py'],
                      'whatsapp': ['services/whatsapp.py', 'services/refiloe.py'],
                      'dashboard': ['routes/dashboard.py'],
                      'app': ['app.py'],
                      'deployment': ['services/refiloe.py', 'app.py', 'requirements.txt'],
                      'crash': ['services/refiloe.py', 'app.py'],
                      'database': ['models/', 'supabase/migrations/'],
                      'schema': ['supabase/migrations/'],
                      'service': ['services/'],
                      'route': ['routes/'],
                      'template': ['templates/']
                  }
                  
                  # Find relevant files based on keywords
                  for keyword, paths in keyword_mappings.items():
                      if keyword in task_lower:
                          for path in paths:
                              if path.endswith('/'):
                                  # Directory - add all files in it
                                  for file_path in all_files.keys():
                                      if file_path.startswith(path):
                                          relevant_files.add(file_path)
                              elif path in all_files:
                                  relevant_files.add(path)
                  
                  # Add specifically mentioned files
                  for file_path in all_files.keys():
                      if file_path in task or Path(file_path).stem in task_lower:
                          relevant_files.add(file_path)
                  
                  # Default files if nothing found
                  if not relevant_files:
                      if 'app.py' in all_files:
                          relevant_files.add('app.py')
                      if 'services/refiloe.py' in all_files:
                          relevant_files.add('services/refiloe.py')
                  
                  # Add files with line numbers for targeted edits
                  for file_path in sorted(relevant_files):
                      if file_path in all_files:
                          context += f"\n=== FILE: {file_path} ===\n"
                          lines = all_files[file_path].split('\n')
                          
                          # Check if file exceeds 600 lines
                          if len(lines) > 600:
                              context += f"‚ö†Ô∏è WARNING: This file has {len(lines)} lines (exceeds 600 line limit)\n"
                              context += "Consider splitting this file into smaller modules.\n\n"
                          
                          # Include file with line numbers
                          for i, line in enumerate(lines, 1):
                              context += f"{i:4}: {line}\n"
                  
                  return context
              
              # FULL context (Opus - comprehensive)
              else:
                  context += "\n=== FULL CODEBASE ===\n"
                  total_size = len(context)
                  max_size = 400000  # Increased for Opus with more tokens
                  
                  for file_path, content in sorted(all_files.items()):
                      if total_size + len(content) < max_size:
                          lines = content.split('\n')
                          
                          # Warn about large files
                          if len(lines) > 600:
                              context += f"\n‚ö†Ô∏è FILE TOO LARGE: {file_path} ({len(lines)} lines)\n"
                          
                          context += f"\n{'='*60}\nFILE: {file_path}\n{'='*60}\n"
                          context += content
                          context += f"\n{'='*60}\n"
                          total_size += len(content)
                  
                  return context
          
          # Read project files
          print("\nüìÇ Reading project files...")
          all_project_files = {}
          
          # Get all relevant files
          for pattern in ['*.py', '*.txt', '*.md', '*.yml', '*.yaml', '*.sql', '*.json', '*.html']:
              for file in Path('.').rglob(pattern):
                  if not str(file).startswith('.git'):
                      try:
                          with open(file, 'r', encoding='utf-8') as f:
                              all_project_files[str(file)] = f.read()
                      except:
                          pass
          
          print(f"üìö Found {len(all_project_files)} files")
          
          # Build context
          context = build_context_for_model(clean_task, all_project_files, context_level)
          
          # Calculate costs
          estimated_tokens = len(context) / 4
          if "opus" in selected_model:
              cost_per_million = 15
          elif "sonnet" in selected_model:
              cost_per_million = 3
          else:  # haiku
              cost_per_million = 0.25
          
          estimated_cost = (estimated_tokens / 1_000_000) * cost_per_million
          
          print(f"\nüìä Context size: {len(context):,} chars")
          print(f"ü™ô Estimated tokens: {estimated_tokens:,.0f}")
          print(f"üí∞ Estimated cost: ${estimated_cost:.4f} ({model_name})")
          
          try:
              client = anthropic.Anthropic()
              
              # Build prompt with multi-step awareness
              prompt = f'''You are helping with Refiloe, a WhatsApp AI assistant for South African personal trainers.
              
              Tech Stack: Python Flask, Supabase, Railway, WhatsApp Business API
              Context: South African (Rand currency, +27 phones)
              Model: You are {model_name}
              {"Multi-Step Task: Step " + str(current_step) + " of " + str(len(steps)) if is_multi_step else ""}
              
              CRITICAL RULES:
              1. No file should exceed 600 lines
              2. Use TARGETED EDITS for existing files (show only changed sections)
              3. Provide COMPLETE content only for NEW files
              4. If a file needs splitting, create multiple smaller files
              5. For multi-step tasks, focus ONLY on the current step
              6. Indicate if more steps remain with "CONTINUE_NEEDED"
              
              TASK: {clean_task}
              
              {context}
              
              Provide your response in this EXACT format:
              
              ## ANALYSIS
              [Brief analysis of what needs to be done{"for this step" if is_multi_step else ""}]
              
              ## CHANGES NEEDED
              
              For EXISTING files (use targeted edits):
              
              ### EDIT: path/to/file.py
              
              **Change 1:** [Description]
              Location: Lines X-Y (or function/class name)
              ```python
              # REMOVE (lines X-Y):
              [exact code to remove]
              
              # ADD:
              [exact code to add]
              ```
              
              For NEW files (provide complete content):
              
              ### NEW FILE: path/to/new_file.py
              ```python
              [Complete file content]
              ```
              
              For FILES TO SPLIT (if over 600 lines):
              
              ### SPLIT FILE: path/to/large_file.py
              Split into:
              - path/to/large_file_part1.py (lines 1-300)
              - path/to/large_file_part2.py (lines 301-600)
              - path/to/large_file_part3.py (lines 601+)
              
              ## MIGRATION: optional_migration_name.sql
              ```sql
              [SQL migration if needed]
              ```
              
              ## SUMMARY
              [Brief summary of changes made{"in this step" if is_multi_step else ""}]
              
              {"## CONTINUE_NEEDED" if is_multi_step and current_step < len(steps) else ""}
              {"Next step: " + steps[current_step] if is_multi_step and current_step < len(steps) else ""}
              {"Run @claude @continue to proceed with next step" if is_multi_step and current_step < len(steps) else ""}
              
              IMPORTANT:
              - Use line numbers from the context provided
              - Keep edits focused and minimal
              - If fixing errors, only change the problematic lines
              - For files >600 lines, suggest splitting into logical modules
              {"- Focus ONLY on: " + steps[current_step - 1] if is_multi_step and current_step <= len(steps) else ""}
              '''
              
              print(f"\nü§ñ Calling {model_name} with {max_tokens:,} max tokens...")
              if is_multi_step:
                  print(f"üìç Working on step {current_step} of {len(steps)}")
              
              # FIX FOR STREAMING ERROR - Use streaming for long operations
              response_text = ""
              try:
                  # Determine if streaming is needed
                  use_streaming = (
                      "opus" in selected_model or 
                      is_multi_step or 
                      estimated_tokens > 50000 or
                      len(context) > 100000
                  )
                  
                  if use_streaming:
                      print("üì° Using streaming mode for long operation...")
                      
                      # Stream the response
                      with client.messages.stream(
                          model=selected_model,
                          max_tokens=max_tokens,
                          messages=[{'role': 'user', 'content': prompt}]
                      ) as stream:
                          for text in stream.text_stream:
                              response_text += text
                              # Show progress
                              if len(response_text) % 1000 == 0:
                                  print(".", end="", flush=True)
                      print()  # New line after progress dots
                  else:
                      # Use regular non-streaming for simple tasks
                      print("‚ö° Using standard mode for quick operation...")
                      response = client.messages.create(
                          model=selected_model,
                          max_tokens=max_tokens,
                          messages=[{'role': 'user', 'content': prompt}]
                      )
                      response_text = response.content[0].text
                  
                  print(f"‚úì Received response: {len(response_text)} chars")
                  
              except Exception as api_error:
                  # Better error handling - building string line by line to avoid YAML issues
                  error_str = str(api_error).lower()
                  if "streaming" in error_str or "timeout" in error_str:
                      print("‚è±Ô∏è Request timed out - task too complex")
                      response_text = "## ANALYSIS\n"
                      response_text += "The task is too complex for a single operation.\n\n"
                      response_text += "## RECOMMENDATION\n"
                      response_text += "Break the task into smaller parts.\n\n"
                      response_text += "Option 1 - Analyze first without applying\n"
                      response_text += "@claude (without @apply) to analyze\n\n"
                      response_text += "Option 2 - Fix one file at a time\n"
                      response_text += "@claude @apply fix syntax errors in services/refiloe.py\n\n"
                      response_text += "Option 3 - Use multi-step approach\n"
                      response_text += "@claude @apply step 1 analyze and fix critical errors\n"
                      response_text += "Then run @claude @continue @apply\n"
                  else:
                      raise api_error
              
              # Check if continuation is needed
              continue_needed = "CONTINUE_NEEDED" in response_text or (is_multi_step and current_step < len(steps))
              
              # Save context for potential continuation (SOLUTION 5 & 6)
              if continue_needed:
                  context_data = {
                      'task': clean_task if not is_multi_step else task.replace('@continue', '').strip(),
                      'model': selected_model,
                      'current_step': current_step,
                      'total_steps': len(steps) if is_multi_step else 1,
                      'steps': steps,
                      'timestamp': datetime.now().isoformat()
                  }
                  with open('claude_context.json', 'w') as f:
                      json.dump(context_data, f)
                  print(f"üíæ Context saved for continuation (step {current_step + 1} of {len(steps)})")
              elif Path('claude_context.json').exists():
                  # Remove context file if task is complete
                  os.remove('claude_context.json')
                  print("‚úÖ Task completed, context cleared")
              
              # Save response
              with open('claude_response.md', 'w', encoding='utf-8') as f:
                  f.write(f"<!-- Model: {model_name} -->\n")
                  f.write(f"<!-- Cost: ${estimated_cost:.4f} -->\n")
                  f.write(f"<!-- Max Tokens: {max_tokens} -->\n")
                  if is_multi_step:
                      f.write(f"<!-- Step {current_step} of {len(steps)} -->\n")
                  if continue_needed:
                      f.write(f"<!-- CONTINUATION NEEDED -->\n")
                  f.write(response_text)
              
              # Apply changes if requested
              changes_applied = []
              
              if auto_apply:
                  print("\nüìù Applying targeted changes...")
                  
                  # Parse EDIT sections (targeted changes)
                  edit_pattern = r'### EDIT:\s*(.+?)\n.*?```python\n# REMOVE.*?:\n(.*?)\n\n# ADD:\n(.*?)\n```'
                  
                  for match in re.finditer(edit_pattern, response_text, re.DOTALL):
                      file_path = match.group(1).strip()
                      old_code = match.group(2).strip()
                      new_code = match.group(3).strip()
                      
                      try:
                          if Path(file_path).exists():
                              with open(file_path, 'r', encoding='utf-8') as f:
                                  content = f.read()
                              
                              # Apply the replacement
                              if old_code in content:
                                  content = content.replace(old_code, new_code)
                                  with open(file_path, 'w', encoding='utf-8') as f:
                                      f.write(content)
                                  changes_applied.append(f"Updated {file_path}")
                                  print(f"‚úì Applied edit to: {file_path}")
                              else:
                                  print(f"‚ö†Ô∏è Could not find code to replace in {file_path}")
                      except Exception as e:
                          print(f"‚úó Error editing {file_path}: {e}")
                  
                  # Parse NEW FILE sections (complete files)
                  new_file_pattern = r'### NEW FILE:\s*(.+?)\n```(?:python|sql|txt|md|yml|yaml|json|html)?\n(.*?)\n```'
                  
                  for match in re.finditer(new_file_pattern, response_text, re.DOTALL):
                      file_path = match.group(1).strip()
                      content = match.group(2)
                      
                      try:
                          Path(file_path).parent.mkdir(parents=True, exist_ok=True)
                          with open(file_path, 'w', encoding='utf-8') as f:
                              f.write(content)
                          changes_applied.append(f"Created {file_path}")
                          print(f"‚úì Created: {file_path}")
                      except Exception as e:
                          print(f"‚úó Error creating {file_path}: {e}")
                  
                  # Handle migrations
                  migration_pattern = r'## MIGRATION:\s*(.+?)\n```sql\n(.*?)\n```'
                  
                  for match in re.finditer(migration_pattern, response_text, re.DOTALL):
                      migration_name = match.group(1).strip()
                      content = match.group(2)
                      
                      try:
                          Path('supabase/migrations').mkdir(parents=True, exist_ok=True)
                          timestamp = datetime.now().strftime('%Y%m%d%H%M%S')
                          migration_file = f"supabase/migrations/{timestamp}_{migration_name}.sql"
                          
                          with open(migration_file, 'w', encoding='utf-8') as f:
                              f.write(content)
                          changes_applied.append(f"Created migration {migration_file}")
                          print(f"‚úì Created migration: {migration_file}")
                      except Exception as e:
                          print(f"‚úó Error creating migration: {e}")
              
              # Prepare summary
              if changes_applied:
                  summary = f"‚úÖ **Changes Applied:**\n"
                  for change in changes_applied:
                      summary += f"- {change}\n"
              else:
                  summary = "üìã **Analysis Complete**\n"
                  if not auto_apply:
                      summary += "üí° Add `@apply` to apply changes\n"
              
              # Add step progress for multi-step tasks
              if is_multi_step:
                  summary += f"\nüìä **Progress:** Step {current_step} of {len(steps)} completed\n"
                  if current_step < len(steps):
                      summary += f"üìç **Next:** {steps[current_step]}\n"
              
              # Add continuation notice if needed
              if continue_needed:
                  summary += f"\n‚ö†Ô∏è **More steps needed!**\n"
                  summary += f"Run `@claude @continue` to proceed with "
                  if is_multi_step:
                      summary += f"step {current_step + 1} of {len(steps)}\n"
                  else:
                      summary += "remaining changes\n"
              
              # Add cost info
              summary += f"\nü§ñ **Model:** {model_name}\n"
              summary += f"üí∞ **Cost:** ${estimated_cost:.4f}\n"
              summary += f"üî¢ **Max Tokens:** {max_tokens:,}\n"
              
              # Save summary
              with open('summary.txt', 'w', encoding='utf-8') as f:
                  f.write(summary)
              
              # Commit if needed
              if auto_apply and changes_applied:
                  try:
                      subprocess.run(['git', 'add', '.'], check=True)
                      
                      if is_multi_step:
                          commit_msg = f"ü§ñ {model_name}: Step {current_step}/{len(steps)} - {clean_task[:30]}..."
                      else:
                          commit_msg = f"ü§ñ {model_name}: {clean_task[:50]}..."
                      
                      subprocess.run(['git', 'commit', '-m', commit_msg], check=True)
                      
                      if create_pr:
                          branch_name = f"claude-fix-{datetime.now().strftime('%Y%m%d%H%M%S')}"
                          subprocess.run(['git', 'checkout', '-b', branch_name], check=True)
                          subprocess.run(['git', 'push', 'origin', branch_name], check=True)
                          with open('pr_created.txt', 'w') as f:
                              f.write(branch_name)
                      else:
                          subprocess.run(['git', 'push'], check=True)
                      
                      print("‚úì Changes committed!")
                  except Exception as e:
                      print(f"‚úó Git error: {e}")
              
              # Save response for comment
              with open('response.txt', 'w', encoding='utf-8') as f:
                  if len(response_text) > 50000:
                      f.write(response_text[:50000] + "\n\n[... see claude_response.md for full response]")
                  else:
                      f.write(response_text)
                  
          except Exception as e:
              error_msg = str(e)
              print(f"‚úó Error: {error_msg}")
              
              with open('summary.txt', 'w', encoding='utf-8') as f:
                  f.write(f"‚ùå Error: {error_msg}")
              with open('response.txt', 'w', encoding='utf-8') as f:
                  f.write(f"Error: {error_msg}")
          PYTHON_SCRIPT
      
      - name: Post Response
        uses: actions/github-script@v6
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const fs = require('fs');
            
            let summary = '';
            let response = '';
            let prBranch = '';
            
            try {
              if (fs.existsSync('summary.txt')) {
                summary = fs.readFileSync('summary.txt', 'utf8');
              }
              if (fs.existsSync('response.txt')) {
                response = fs.readFileSync('response.txt', 'utf8');
              }
              if (fs.existsSync('pr_created.txt')) {
                prBranch = fs.readFileSync('pr_created.txt', 'utf8');
              }
            } catch (e) {
              console.log('Error reading files:', e);
            }
            
            let comment = `ü§ñ **Claude Response:**\n\n${summary}\n`;
            
            if (prBranch) {
              comment += `\nüîó **Pull Request:** Create PR from branch \`${prBranch}\`\n`;
            }
            
            comment += `\n<details>\n<summary>üìÑ Full Analysis</summary>\n\n${response}\n</details>`;
            
            await github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            })

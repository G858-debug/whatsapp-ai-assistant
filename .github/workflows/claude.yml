name: Claude Code Assistant
on:
  issue_comment:
    types: [created]

permissions:
  contents: write
  issues: write
  pull-requests: write

jobs:
  claude:
    if: contains(github.event.comment.body, '@claude')
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          fetch-depth: 0
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Install Dependencies
        run: |
          pip install anthropic
          pip install supabase
          pip install gitpython
          pip install unidiff
      
      - name: Configure Git
        run: |
          git config --global user.name "Claude Assistant"
          git config --global user.email "claude@github-actions.bot"
      
      - name: Save comment to file
        run: |
          cat > comment.txt << 'ENDOFCOMMENT'
          ${{ github.event.comment.body }}
          ENDOFCOMMENT
      
      - name: Process with Claude and Apply Changes
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          python - <<'PYTHON_SCRIPT'
          import anthropic
          import os
          import json
          import re
          from pathlib import Path
          import subprocess
          from datetime import datetime
          
          # Read the task
          with open('comment.txt', 'r') as f:
              comment = f.read()
          task = comment.replace('@claude', '').strip()
          
          print(f"📋 Task: {task}")
          
          # Check for special commands
          auto_apply = '@apply' in comment or '@commit' in comment
          create_pr = '@pr' in comment
          force_opus = '@opus' in comment
          force_sonnet = '@sonnet' in comment
          force_haiku = '@haiku' in comment
          continue_task = '@continue' in comment  # SOLUTION 5: Continue command
          
          # Remove command keywords from task
          clean_task = task.replace('@apply', '').replace('@commit', '').replace('@pr', '')\
                           .replace('@opus', '').replace('@sonnet', '').replace('@haiku', '')\
                           .replace('@continue', '').strip()
          
          # SOLUTION 5: Handle continue command
          if continue_task:
              # Check for previous context
              if Path('claude_context.json').exists():
                  with open('claude_context.json', 'r') as f:
                      previous_context = json.load(f)
                  print(f"📂 Continuing from previous task: {previous_context.get('task', 'unknown')}")
                  clean_task = f"Continue from previous task: {previous_context['task']}\n\nRemaining work:\n{previous_context.get('remaining_work', 'Complete the implementation')}"
                  # Use the same model as before if specified
                  if previous_context.get('model'):
                      if 'opus' in previous_context['model']:
                          force_opus = True
                      elif 'sonnet' in previous_context['model']:
                          force_sonnet = True
                      elif 'haiku' in previous_context['model']:
                          force_haiku = True
              else:
                  print("⚠️ No previous context found for @continue")
                  clean_task = "No previous context found. Please specify what to continue."
          
          # =====================================
          # ENHANCED MODEL SELECTION WITH INCREASED TOKENS (SOLUTION 1)
          # =====================================
          def select_model_and_context(task, comment):
              """Select model based on task complexity with increased token limits"""
              
              task_lower = task.lower()
              
              # Force model if specified
              if force_opus:
                  print("🎯 Force flag: Using Opus 4.1")
                  return 'claude-opus-4-1-20250805', 16000, 'full', "Opus 4.1 (forced)"  # Increased from 8000
              
              if force_sonnet:
                  print("🎯 Force flag: Using Sonnet 3.5")
                  return 'claude-3-5-sonnet-20241022', 8000, 'targeted', "Sonnet 3.5 (forced)"  # Increased from 4000
              
              if force_haiku:
                  print("🎯 Force flag: Using Haiku 3")
                  return 'claude-3-haiku-20240307', 4000, 'minimal', "Haiku 3 (forced)"  # Increased from 2000
              
              # HAIKU 3 TRIGGERS (Ultra-simple tasks - $0.25/million tokens)
              haiku_triggers = [
                  # Trivial fixes
                  'fix typo', 'fix spelling', 'update comment', 'fix comma',
                  'add space', 'remove space', 'fix quote', 'fix bracket',
                  'fix emoji', 'fix string', 'fix f-string',
                  
                  # Simple string/text changes
                  'change text', 'update string', 'rename variable',
                  'update version', 'change url', 'fix link',
                  
                  # Documentation only
                  'add comment', 'update readme', 'fix markdown', 'add docstring',
                  
                  # Formatting
                  'format code', 'fix whitespace', 'align code', 'fix tabs'
              ]
              
              # SONNET 3.5 TRIGGERS (Moderate tasks - $3/million tokens)
              sonnet_triggers = [
                  # Single function fixes
                  'fix function', 'update method', 'fix indentation', 'indentationerror',
                  'syntax error', 'fix import', 'add validation', 'add check',
                  'fix payment', 'fix error in', 'deployment crash',
                  
                  # Simple features
                  'add endpoint', 'simple feature', 'add field', 'update model',
                  'single file', 'one file', 'specific function',
                  
                  # Small refactors
                  'extract function', 'rename class', 'move function',
                  'split function', 'combine functions'
              ]
              
              # OPUS 4.1 TRIGGERS (Complex tasks - $15/million tokens)
              opus_triggers = [
                  # Architecture & Design
                  'architect', 'design system', 'restructure', 'refactor entire',
                  
                  # Multi-file operations
                  'all files', 'entire codebase', 'multiple services', 'full system',
                  'complete implementation', 'finish all',
                  
                  # Complex analysis
                  'analyze', 'investigate', 'debug complex', 'trace bug',
                  'performance', 'security audit', 'code review',
                  
                  # Integration & Features
                  'integrate', 'implement full', 'build complete', 'create system'
              ]
              
              # Check triggers
              is_haiku = any(trigger in task_lower for trigger in haiku_triggers)
              is_sonnet = any(trigger in task_lower for trigger in sonnet_triggers)
              is_opus = any(trigger in task_lower for trigger in opus_triggers)
              
              # Decision logic with increased token limits
              if is_haiku and not is_sonnet and not is_opus:
                  return 'claude-3-haiku-20240307', 4000, 'minimal', "Trivial task (Haiku 3)"
              elif is_sonnet and not is_opus:
                  return 'claude-3-5-sonnet-20241022', 8000, 'targeted', "Moderate task (Sonnet 3.5)"
              elif is_opus:
                  return 'claude-opus-4-1-20250805', 16000, 'full', "Complex task (Opus 4.1)"
              elif len(task) < 50:
                  return 'claude-3-haiku-20240307', 4000, 'minimal', "Short request (Haiku 3)"
              elif len(task) < 150:
                  return 'claude-3-5-sonnet-20241022', 8000, 'targeted', "Standard task (Sonnet 3.5)"
              else:
                  return 'claude-opus-4-1-20250805', 16000, 'full', "Long request (Opus 4.1)"
          
          # Select model
          selected_model, max_tokens, context_level, model_reason = select_model_and_context(task, comment)
          model_name = "Opus 4.1" if "opus" in selected_model else "Sonnet 3.5" if "sonnet" in selected_model else "Haiku 3"
          
          print(f"🤖 Model: {model_name}")
          print(f"📝 Reason: {model_reason}")
          print(f"🔢 Max tokens: {max_tokens:,}")
          
          # =====================================
          # CONTEXT BUILDING BASED ON MODEL
          # =====================================
          def build_context_for_model(task, all_files, context_level):
              """Build appropriate context based on model/task"""
              
              task_lower = task.lower()
              
              # Always start with structure
              context = "=== PROJECT STRUCTURE ===\n"
              for file_path in sorted(all_files.keys())[:50]:  # Limit structure list
                  context += f"- {file_path}\n"
              
              # MINIMAL context (Haiku - just target file)
              if context_level == 'minimal':
                  # Find the specific file mentioned
                  target_file = None
                  for file_path in all_files.keys():
                      if file_path in task or Path(file_path).stem in task_lower:
                          target_file = file_path
                          break
                  
                  # Default to services/refiloe.py if it's a deployment error
                  if not target_file and 'deployment' in task_lower:
                      target_file = 'services/refiloe.py'
                  
                  if target_file and target_file in all_files:
                      context += f"\n=== TARGET FILE: {target_file} ===\n"
                      # For minimal context, include line numbers
                      lines = all_files[target_file].split('\n')
                      for i, line in enumerate(lines, 1):
                          context += f"{i:4}: {line}\n"
                  return context
              
              # TARGETED context (Sonnet - relevant files only)
              elif context_level == 'targeted':
                  relevant_files = set()
                  
                  # Keyword mappings
                  keyword_mappings = {
                      'payment': ['payment_manager.py', 'services/payment.py'],
                      'gamification': ['services/gamification.py', 'routes/dashboard.py'],
                      'assessment': ['services/assessment.py'],
                      'refiloe': ['services/refiloe.py'],
                      'whatsapp': ['services/whatsapp.py', 'services/refiloe.py'],
                      'dashboard': ['routes/dashboard.py'],
                      'app': ['app.py'],
                      'deployment': ['services/refiloe.py', 'app.py'],
                      'crash': ['services/refiloe.py', 'app.py']
                  }
                  
                  # Find relevant files
                  for keyword, paths in keyword_mappings.items():
                      if keyword in task_lower:
                          for path in paths:
                              if path in all_files:
                                  relevant_files.add(path)
                  
                  # Add specifically mentioned files
                  for file_path in all_files.keys():
                      if file_path in task or Path(file_path).stem in task_lower:
                          relevant_files.add(file_path)
                  
                  # Default to app.py and services/refiloe.py if nothing found
                  if not relevant_files:
                      if 'app.py' in all_files:
                          relevant_files.add('app.py')
                      if 'services/refiloe.py' in all_files:
                          relevant_files.add('services/refiloe.py')
                  
                  # Add files with line numbers for targeted edits
                  for file_path in sorted(relevant_files):
                      if file_path in all_files:
                          context += f"\n=== FILE: {file_path} ===\n"
                          lines = all_files[file_path].split('\n')
                          
                          # Check if file exceeds 600 lines
                          if len(lines) > 600:
                              context += f"⚠️ WARNING: This file has {len(lines)} lines (exceeds 600 line limit)\n"
                              context += "Consider splitting this file into smaller modules.\n\n"
                          
                          # Include file with line numbers
                          for i, line in enumerate(lines, 1):
                              context += f"{i:4}: {line}\n"
                  
                  return context
              
              # FULL context (Opus - comprehensive)
              else:
                  context += "\n=== FULL CODEBASE ===\n"
                  total_size = len(context)
                  max_size = 400000  # Increased from 300000 for Opus with more tokens
                  
                  for file_path, content in sorted(all_files.items()):
                      if total_size + len(content) < max_size:
                          lines = content.split('\n')
                          
                          # Warn about large files
                          if len(lines) > 600:
                              context += f"\n⚠️ FILE TOO LARGE: {file_path} ({len(lines)} lines)\n"
                          
                          context += f"\n{'='*60}\nFILE: {file_path}\n{'='*60}\n"
                          context += content
                          context += f"\n{'='*60}\n"
                          total_size += len(content)
                  
                  return context
          
          # Read project files
          print("\n📂 Reading project files...")
          all_project_files = {}
          
          # Get all relevant files
          for pattern in ['*.py', '*.txt', '*.md', '*.yml', '*.yaml', '*.sql', '*.json']:
              for file in Path('.').rglob(pattern):
                  if not str(file).startswith('.git'):
                      try:
                          with open(file, 'r', encoding='utf-8') as f:
                              all_project_files[str(file)] = f.read()
                      except:
                          pass
          
          print(f"📚 Found {len(all_project_files)} files")
          
          # Build context
          context = build_context_for_model(clean_task, all_project_files, context_level)
          
          # Calculate costs
          estimated_tokens = len(context) / 4
          if "opus" in selected_model:
              cost_per_million = 15
          elif "sonnet" in selected_model:
              cost_per_million = 3
          else:  # haiku
              cost_per_million = 0.25
          
          estimated_cost = (estimated_tokens / 1_000_000) * cost_per_million
          
          print(f"\n📊 Context size: {len(context):,} chars")
          print(f"🪙 Estimated tokens: {estimated_tokens:,.0f}")
          print(f"💰 Estimated cost: ${estimated_cost:.4f} ({model_name})")
          
          try:
              client = anthropic.Anthropic()
              
              # Build prompt with continuation support
              prompt = f'''You are helping with Refiloe, a WhatsApp AI assistant for South African personal trainers.
              
              Tech Stack: Python Flask, Supabase, Railway, WhatsApp Business API
              Context: South African (Rand currency, +27 phones)
              Model: You are {model_name}
              
              CRITICAL RULES:
              1. No file should exceed 600 lines
              2. Use TARGETED EDITS for existing files (show only changed sections)
              3. Provide COMPLETE content only for NEW files
              4. If a file needs splitting, create multiple smaller files
              5. If changes are too extensive for one response, indicate "CONTINUE_NEEDED" at the end
              
              TASK: {clean_task}
              
              {context}
              
              Provide your response in this EXACT format:
              
              ## ANALYSIS
              [Brief analysis of what needs to be done]
              
              ## CHANGES NEEDED
              
              For EXISTING files (use targeted edits):
              
              ### EDIT: path/to/file.py
              
              **Change 1:** [Description]
              Location: Lines X-Y (or function/class name)
              ```python
              # REMOVE (lines X-Y):
              [exact code to remove]
              
              # ADD:
              [exact code to add]
              ```
              
              For NEW files (provide complete content):
              
              ### NEW FILE: path/to/new_file.py
              ```python
              [Complete file content]
              ```
              
              For FILES TO SPLIT (if over 600 lines):
              
              ### SPLIT FILE: path/to/large_file.py
              Split into:
              - path/to/large_file_part1.py (lines 1-300)
              - path/to/large_file_part2.py (lines 301-600)
              - path/to/large_file_part3.py (lines 601+)
              
              ## MIGRATION: optional_migration_name.sql
              ```sql
              [SQL migration if needed]
              ```
              
              ## SUMMARY
              [Brief summary of changes made]
              
              ## CONTINUE_NEEDED
              [If more changes are needed, list them here and say "Run @claude @continue to complete"]
              
              IMPORTANT:
              - Use line numbers from the context provided
              - Keep edits focused and minimal
              - If fixing errors, only change the problematic lines
              - For files >600 lines, suggest splitting into logical modules
              - If you can't complete all changes, indicate what remains
              '''
              
              print(f"\n🤖 Calling {model_name} with {max_tokens:,} max tokens...")
              response = client.messages.create(
                  model=selected_model,
                  max_tokens=max_tokens,
                  messages=[{'role': 'user', 'content': prompt}]
              )
              
              response_text = response.content[0].text
              print(f"✓ Received response: {len(response_text)} chars")
              
              # Check if continuation is needed
              continue_needed = "CONTINUE_NEEDED" in response_text or "Run @claude @continue" in response_text
              
              # Save context for potential continuation (SOLUTION 5)
              if continue_needed:
                  # Extract remaining work from response
                  remaining_work = ""
                  if "## CONTINUE_NEEDED" in response_text:
                      remaining_work = response_text.split("## CONTINUE_NEEDED")[1].strip()
                  
                  context_data = {
                      'task': clean_task,
                      'model': selected_model,
                      'remaining_work': remaining_work,
                      'timestamp': datetime.now().isoformat()
                  }
                  with open('claude_context.json', 'w') as f:
                      json.dump(context_data, f)
                  print("💾 Context saved for continuation")
              
              # Save response
              with open('claude_response.md', 'w', encoding='utf-8') as f:
                  f.write(f"<!-- Model: {model_name} -->\n")
                  f.write(f"<!-- Cost: ${estimated_cost:.4f} -->\n")
                  f.write(f"<!-- Max Tokens: {max_tokens} -->\n")
                  if continue_needed:
                      f.write(f"<!-- CONTINUATION NEEDED -->\n")
                  f.write(response_text)
              
              # Apply changes if requested
              changes_applied = []
              
              if auto_apply:
                  print("\n📝 Applying targeted changes...")
                  
                  # Parse EDIT sections (targeted changes)
                  edit_pattern = r'### EDIT:\s*(.+?)\n.*?```python\n# REMOVE.*?:\n(.*?)\n\n# ADD:\n(.*?)\n```'
                  
                  for match in re.finditer(edit_pattern, response_text, re.DOTALL):
                      file_path = match.group(1).strip()
                      old_code = match.group(2).strip()
                      new_code = match.group(3).strip()
                      
                      try:
                          if Path(file_path).exists():
                              with open(file_path, 'r', encoding='utf-8') as f:
                                  content = f.read()
                              
                              # Apply the replacement
                              if old_code in content:
                                  content = content.replace(old_code, new_code)
                                  with open(file_path, 'w', encoding='utf-8') as f:
                                      f.write(content)
                                  changes_applied.append(f"Updated {file_path}")
                                  print(f"✓ Applied edit to: {file_path}")
                              else:
                                  print(f"⚠️ Could not find code to replace in {file_path}")
                      except Exception as e:
                          print(f"✗ Error editing {file_path}: {e}")
                  
                  # Parse NEW FILE sections (complete files)
                  new_file_pattern = r'### NEW FILE:\s*(.+?)\n```(?:python|sql|txt|md|yml|yaml|json)?\n(.*?)\n```'
                  
                  for match in re.finditer(new_file_pattern, response_text, re.DOTALL):
                      file_path = match.group(1).strip()
                      content = match.group(2)
                      
                      try:
                          Path(file_path).parent.mkdir(parents=True, exist_ok=True)
                          with open(file_path, 'w', encoding='utf-8') as f:
                              f.write(content)
                          changes_applied.append(f"Created {file_path}")
                          print(f"✓ Created: {file_path}")
                      except Exception as e:
                          print(f"✗ Error creating {file_path}: {e}")
                  
                  # Handle migrations
                  migration_pattern = r'## MIGRATION:\s*(.+?)\n```sql\n(.*?)\n```'
                  
                  for match in re.finditer(migration_pattern, response_text, re.DOTALL):
                      migration_name = match.group(1).strip()
                      content = match.group(2)
                      
                      try:
                          Path('supabase/migrations').mkdir(parents=True, exist_ok=True)
                          timestamp = datetime.now().strftime('%Y%m%d%H%M%S')
                          migration_file = f"supabase/migrations/{timestamp}_{migration_name}.sql"
                          
                          with open(migration_file, 'w', encoding='utf-8') as f:
                              f.write(content)
                          changes_applied.append(f"Created migration {migration_file}")
                          print(f"✓ Created migration: {migration_file}")
                      except Exception as e:
                          print(f"✗ Error creating migration: {e}")
              
              # Prepare summary
              if changes_applied:
                  summary = f"✅ **Changes Applied:**\n"
                  for change in changes_applied:
                      summary += f"- {change}\n"
              else:
                  summary = "📋 **Analysis Complete**\n"
                  if not auto_apply:
                      summary += "💡 Add `@apply` to apply changes\n"
              
              # Add continuation notice if needed
              if continue_needed:
                  summary += f"\n⚠️ **More changes needed!**\n"
                  summary += f"Run `@claude @continue` to complete remaining changes.\n"
              
              # Add cost info
              summary += f"\n🤖 **Model:** {model_name}\n"
              summary += f"💰 **Cost:** ${estimated_cost:.4f}\n"
              summary += f"🔢 **Max Tokens:** {max_tokens:,}\n"
              
              # Save summary
              with open('summary.txt', 'w', encoding='utf-8') as f:
                  f.write(summary)
              
              # Commit if needed
              if auto_apply and changes_applied:
                  try:
                      subprocess.run(['git', 'add', '.'], check=True)
                      commit_msg = f"🤖 {model_name}: {clean_task[:50]}..."
                      subprocess.run(['git', 'commit', '-m', commit_msg], check=True)
                      
                      if create_pr:
                          branch_name = f"claude-fix-{datetime.now().strftime('%Y%m%d%H%M%S')}"
                          subprocess.run(['git', 'checkout', '-b', branch_name], check=True)
                          subprocess.run(['git', 'push', 'origin', branch_name], check=True)
                          with open('pr_created.txt', 'w') as f:
                              f.write(branch_name)
                      else:
                          subprocess.run(['git', 'push'], check=True)
                      
                      print("✓ Changes committed!")
                  except Exception as e:
                      print(f"✗ Git error: {e}")
              
              # Save response for comment
              with open('response.txt', 'w', encoding='utf-8') as f:
                  if len(response_text) > 50000:
                      f.write(response_text[:50000] + "\n\n[... see claude_response.md for full response]")
                  else:
                      f.write(response_text)
                  
          except Exception as e:
              error_msg = str(e)
              print(f"✗ Error: {error_msg}")
              
              with open('summary.txt', 'w', encoding='utf-8') as f:
                  f.write(f"❌ Error: {error_msg}")
              with open('response.txt', 'w', encoding='utf-8') as f:
                  f.write(f"Error: {error_msg}")
          PYTHON_SCRIPT
      
      - name: Post Response
        uses: actions/github-script@v6
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const fs = require('fs');
            
            let summary = '';
            let response = '';
            let prBranch = '';
            
            try {
              if (fs.existsSync('summary.txt')) {
                summary = fs.readFileSync('summary.txt', 'utf8');
              }
              if (fs.existsSync('response.txt')) {
                response = fs.readFileSync('response.txt', 'utf8');
              }
              if (fs.existsSync('pr_created.txt')) {
                prBranch = fs.readFileSync('pr_created.txt', 'utf8');
              }
            } catch (e) {
              console.log('Error reading files:', e);
            }
            
            let comment = `🤖 **Claude Response:**\n\n${summary}\n`;
            
            if (prBranch) {
              comment += `\n🔗 **Pull Request:** Create PR from branch \`${prBranch}\`\n`;
            }
            
            comment += `\n<details>\n<summary>📄 Full Analysis</summary>\n\n${response}\n</details>`;
            
            await github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            })
